{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yAohXBUxBSMcoMJD6jAZ4wnN7GDJ869G",
      "authorship_tag": "ABX9TyP+tG+2j2xN6iltU8tLr1hg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranshumalik14/ece421-labs-hw/blob/main/labs/lab2/lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2: Neural Networks\n",
        "\n",
        "In this lab, we will be creating a neural network from scratch using NumPy."
      ],
      "metadata": {
        "id": "YtLiBTx7KvEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Neural Networks using Numpy\n",
        "\n",
        "We will consider the usual (but limited) defintion of a neural network as a sequence of fully-connected (or dense) layers consisting of nodes with independent activations, except for possibly the output layer where we may have require a multiclass probability distribution as the output or some similarly inferrable vector; we will exclusively consider this case in the lab to classify the `notMNIST` dataset across all 10 alphabets.\n",
        "\n",
        "We will begin by defining classes for the three central components of any neural network:\n",
        "\n",
        "1.   Layers (here assumed to be linear and characterized by the number of nodes)\n",
        "2.   Activation functions that produce the output at any particular layer\n",
        "3.   Output loss Function that is minimized using gradient descent"
      ],
      "metadata": {
        "id": "NBl4puliM4oc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Helper Functions, Network Definitions, and Initialization"
      ],
      "metadata": {
        "id": "jGWsXc7S6reh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Gff6Ah1DL3Oy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first start with defining the activation functions along with their derivatives, which we will later be able to use in our neural networks during gradient descent (the learning phase)."
      ],
      "metadata": {
        "id": "_P4168HVCneW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# activation functions\n",
        "class ReLU:\n",
        "    # relu = max(x, 0)    \n",
        "    @staticmethod\n",
        "    def __call__(x):\n",
        "        return np.maximum(x, 0)\n",
        "    # derivative of relu\n",
        "    @staticmethod\n",
        "    def prime(x):\n",
        "        return np.where(x > 0.0, 1.0, 0.0)\n",
        "\n",
        "class Softmax:\n",
        "    # softmax = exp(xi)/sum(exp(xj)), applied row-wise to match data\n",
        "    @staticmethod\n",
        "    def __call__(x):\n",
        "        # subtract maximum for numerical stability\n",
        "        # while keeping the relative differences intact\n",
        "        exp = np.exp(x - x.max(axis=1, keepdims=True))\n",
        "        return exp/exp.sum(axis=1, keepdims=True)\n",
        "\n",
        "    # we can not use this method for batch processing since it \n",
        "    # returns the full Jacobian and will be incompatible with\n",
        "    # element-wise products\n",
        "    @staticmethod\n",
        "    def prime(x): # x should be a vector, flat\n",
        "        assert len(x) == 1 or len(x.T) == 1\n",
        "        s = Softmax()(x)\n",
        "        return np.diag(s) - np.outer(s, s)\n",
        "\n",
        "# just as an extension of the lab\n",
        "class Sigmoid:\n",
        "    # sigmoid = 1 / (1 + exp(-x))\n",
        "    @staticmethod\n",
        "    def __call__(x):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "    # derivative of sigmoid\n",
        "    @staticmethod\n",
        "    def prime(x):\n",
        "        sigmoid = Sigmoid()(x)\n",
        "        return sigmoid*(1 - sigmoid)"
      ],
      "metadata": {
        "id": "nFjDwg6nCukr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we define the `Network` class that will be used to define an arbitrary network with dense (fully-connected) layers. The class definition and functionality will expand as we progress through each section. We begin with defining the functions that create the network structure, model parameters, their initialization, and the forward pass through the network.\n",
        "\n",
        "Particularly, in our implementation, we consider the layers ranging from $0\\le l\\le L$ where layer $L$ denotes the output layer and $0$ denotes the input layer. The weights weight $w^{(l)}_{i,j}$ along an edge connecting node $i$ in layer $l-1$ to node $j$ in layer $l$ is considered to be a part of the weight matrix $\\mathbf{W}^{(l)}$ in the conventional row-column indexing. We utilize the Xavier scheme to initialize the weights, where specifically \n",
        "$$w^{(l)}_{i,j} \\sim \\mathcal{N}\\left(0, \\frac{1}{\\frac{n_{\\text{in}} + n_{\\text{out}}}{2}}\\right) \\quad \\text{ for } 0\\le l\\le L,$$\n",
        "where $n_{\\text{in}}$ and $n_{\\text{out}}$ are the number of nodes in the previous layer and number of nodes in the next layer (if any), respectively. Similarly, the biases $\\mathbf{b}^{(l)}$ specify the bias for the summation at each node in layer $l$, and they are initialized to zero according to the Xavier scheme."
      ],
      "metadata": {
        "id": "7CajgVMRH1BU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network:\n",
        "    def __init__(self, layer_sizes, layer_activations):\n",
        "        assert len(layer_activations) == len(layer_sizes)-1\n",
        "        self.sizes   = layer_sizes\n",
        "        self.thetas  = layer_activations\n",
        "\n",
        "        # xavier init scheme\n",
        "        n_out = layer_sizes[1:] + [0]\n",
        "        n_in  = [0] + layer_sizes[:-1]\n",
        "        self.biases  = [np.zeros((1, n)) for n in layer_sizes[1:]] # row-vecs\n",
        "        self.weights = [np.random.randn(m,n)/np.sqrt((n_out[i]+n_in[i])/2) for \n",
        "                        i, (m, n) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:]))]\n",
        "\n",
        "    def fwd_prop(self, X):\n",
        "        X_ell = X   # X_0 (input layer)\n",
        "        for W, b, theta in zip(self.weights, self.biases, self.thetas):\n",
        "            X_ell = theta((X_ell @ W) + b) # compute X_l, 0 < l <= L\n",
        "        return X_ell # X_L (output layer)"
      ],
      "metadata": {
        "id": "i60AbZ7kM-SE"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now define the loss function that we will use to train our model, along with the accuracy model. Like lab 1, we will use the cross entropy loss since it is based on achieving the maximum likelihood estimate of all the target labels, which are assumed to be mutually exlusive, and is therefore fit for the classification task at hand. It is defined as:\n",
        "\n",
        "$$E_{\\text{in}}(\\Omega) =  -\\sum_{n=1}^N \\mathbf{y}_n\\log\\left(\\widehat{\\mathbf{p}}_n\\right)^\\top$$\n",
        "\n",
        "where the row vectors $\\widehat{\\mathbf{p}}_n$ and $\\mathbf{y}_n$ are the predicted distribution and target (one-hot) label for the $n^{\\text{th}}$ out of $N$ samples in our training dataset, and $\\Omega$ is the set of trainable model parameters (weights and biases) in our network."
      ],
      "metadata": {
        "id": "TSNVfnB7Iwdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "class CrossEntropy:\n",
        "    @staticmethod\n",
        "    def __call__(p_hat, ys):\n",
        "        return -np.sum(ys*np.log(p_hat))\n",
        "\n",
        "    # derivative with respect to input (prediction distributions)\n",
        "    @staticmethod\n",
        "    def derivative(p_hat, ys):\n",
        "        return -ys/p_hat\n",
        "\n",
        "    # gradient with respect to s^(3), the input to softmax layer\n",
        "    @staticmethod\n",
        "    def grad_softmaxlogits(logits, ys):\n",
        "        return Softmax()(logits) - ys # p_hat - ys"
      ],
      "metadata": {
        "id": "z28ycr7EPLEB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `accuracy` function is defined below to compute the mean number of misclassifications, giving us an idea of how likely it is for the network to arrive at an incorrect label."
      ],
      "metadata": {
        "id": "9EDfOQALziwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy of prediction\n",
        "def accuracy(p_hat, ys):\n",
        "    return np.mean(np.argmax(ys, axis=1) == np.argmax(p_hat, axis=1))"
      ],
      "metadata": {
        "id": "4a5RHYFSzh67"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will run a forward pass on an untrained, newly initialized, network and test for its accuracy to make sure our implementation is functional thus far. We source the data from section 1.3 just for this purpose."
      ],
      "metadata": {
        "id": "SaSIXe7x41F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create neural network\n",
        "F, H, K = 784, 1000, 10\n",
        "nn = Network([F, H, K], [ReLU(), Softmax()])\n",
        "\n",
        "# forward pass, loss, and accuracy on random init\n",
        "p_hat    = nn.fwd_prop(X_train)\n",
        "accur    = accuracy(p_hat, ys_train)\n",
        "avg_loss = CrossEntropy()(p_hat, ys_train)/X_train.shape[0]\n",
        "print(\"Loss = {}, Accuracy = {}\".format(avg_loss, accur))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC9XcHR45IcX",
        "outputId": "9ee6997f-f4a9-428a-f8f1-7a3cc264e163"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss = 2.8073398781189276, Accuracy = 0.098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Backpropagation Derivation\n",
        "\n",
        "We implement and use the backpropagation algorithm to be able to efficiently perform gradient descent to minimize the loss.\n",
        "\n",
        "Particularly, we will be considering a 3-layer network as defined above in section 1.1. We explicitly derive the gradient of the loss function with respect to the model parameters, to be able to update them. The four gradients we need to compute are: $\\frac{\\partial E_{\\text{in}}}{\\partial \\mathbf{W}^{(2)}}$, $\\frac{\\partial E_{\\text{in}}}{\\mathbf{b}^{(2)}}$, $\\frac{\\partial E_{\\text{in}}}{}$, and $\\frac{\\partial E_{\\text{in}}}{}$."
      ],
      "metadata": {
        "id": "bRSG-YED5RFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# due to time-availability constraints, we will constrain training to an L-layer\n",
        "# network with softmax output activation and cross entropy loss, i.e. not generic\n",
        "def multiclass_CE_back_prop(self, X, ys, loss):\n",
        "    assert isinstance(self.thetas[-1], Softmax)\n",
        "    assert isinstance(loss, CrossEntropy)\n",
        "    # also, we can not support vector activation functions (like softmax) in \n",
        "    # middle layers (and at the input)\n",
        "    for i in range(len(self.thetas)-1):\n",
        "        assert not isinstance(self.thetas[i], Softmax)\n",
        "    \n",
        "    # get summations and activations\n",
        "    X_ells = [X]\n",
        "    S_ells = []\n",
        "    for W, b, theta in zip(self.weights, self.biases, self.thetas):\n",
        "        S_ell = (X_ells[-1] @ W) + b\n",
        "        X_ells.append(theta(S_ell))\n",
        "        S_ells.append(S_ell)\n",
        "    \n",
        "    # create list of gradients (intended to be used in increasing order of layers)\n",
        "    grad_biases  = len(self.biases)*[None]\n",
        "    grad_weights = len(self.weights)*[None]\n",
        "\n",
        "    # backprop:\n",
        "    # start from ell = L (the softmax output layer)\n",
        "    delta_ell = loss.grad_softmaxlogits(S_ells[-1], ys)\n",
        "    grad_biases[-1]  = delta_ell.sum(axis=0)\n",
        "    grad_weights[-1] = X_ells[-2].T @ delta_ell\n",
        "\n",
        "    # continue backwards (0 < ell < L)\n",
        "    for l in range(2, len(self.sizes)):\n",
        "        delta_ell = delta_ell @ self.weights[-l+1].T * self.thetas[-l].prime(S_ells[-l])\n",
        "        grad_biases[-l]  = delta_ell.sum(axis=0)\n",
        "        grad_weights[-l] = X_ells[-l-1].T @ delta_ell\n",
        "\n",
        "    return grad_weights, grad_biases\n",
        "\n",
        "# run batch backprop over a generic (fully-connected) network with vector-valued\n",
        "# activations too; for inspiration see: https://sgugger.github.io/a-simple-neural-net-in-numpy.html\n",
        "def back_prop(self, X, ys):\n",
        "    raise NotImplementedError # todo: for future me\n",
        "    return grad_weights, grad_biases\n",
        "\n",
        "# expand Network definition\n",
        "Network.back_prop = multiclass_CE_back_prop # todo: generic back_prop"
      ],
      "metadata": {
        "id": "ztqBfrR863pf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Learning\n",
        "\n",
        "Training and data"
      ],
      "metadata": {
        "id": "GeXxzhsBPAaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data loader and associated helper functions\n",
        "def loadDataGDrive():\n",
        "    with np.load('/content/drive/MyDrive/Colab Notebooks/notMNIST.npz') as data:\n",
        "        data, targets = data[\"images\"], data[\"labels\"]\n",
        "        \n",
        "        np.random.seed(521)\n",
        "        rand_idx = np.arange(len(data))\n",
        "        np.random.shuffle(rand_idx)\n",
        "        \n",
        "        data = data[rand_idx] / 255.0\n",
        "        targets = targets[rand_idx].astype(int)\n",
        "        \n",
        "        train_data, train_target = data[:10000], targets[:10000]\n",
        "        valid_data, valid_target = data[10000:16000], targets[10000:16000]\n",
        "        test_data, test_target = data[16000:], targets[16000:]\n",
        "        train_target, valid_target, test_target = convert_onehot(train_target, \n",
        "                                                                 valid_target, \n",
        "                                                                 test_target)\n",
        "    return train_data, valid_data, test_data, train_target, valid_target, test_target\n",
        "\n",
        "def convert_onehot(train_target, valid_target, test_target):\n",
        "    new_train = np.zeros((train_target.shape[0], 10))\n",
        "    new_valid = np.zeros((valid_target.shape[0], 10))\n",
        "    new_test = np.zeros((test_target.shape[0], 10))\n",
        "\n",
        "    for item in range(0, train_target.shape[0]):\n",
        "        new_train[item][train_target[item]] = 1\n",
        "    for item in range(0, valid_target.shape[0]):\n",
        "        new_valid[item][valid_target[item]] = 1\n",
        "    for item in range(0, test_target.shape[0]):\n",
        "        new_test[item][test_target[item]] = 1\n",
        "    return new_train, new_valid, new_test\n",
        "\n",
        "# load data\n",
        "x_train, x_valid, x_test, ys_train, ys_valid, ys_test = loadDataGDrive()"
      ],
      "metadata": {
        "id": "USALvma_PC3q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten datavectors\n",
        "X_train = x_train.reshape(x_train.shape[0], -1)\n",
        "X_valid = x_valid.reshape(x_valid.shape[0], -1)\n",
        "X_test  = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "# data for training and testing our neural network\n",
        "Xs = np.array([X_train, X_valid, X_test], dtype=object)    # training, validation, and testing data\n",
        "Ys = np.array([ys_train, ys_valid, ys_test], dtype=object) # training, validation, and testing labels"
      ],
      "metadata": {
        "id": "4rmh5IYe9BEK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_history(title, loss_hist, acc_hist):\n",
        "    # loss_hist = [train_loss, valid_loss, test_loss]\n",
        "    # acc_hist  = [train_acc, valid_acc, test_acc]\n",
        "    f, ax  = plt.subplots(1, 2, figsize=(8,4))\n",
        "    labels = [\"Train\", \"Validation\", \"Test\"]\n",
        "\n",
        "    for i in range(loss_hist.shape[1]):\n",
        "        ax[0].plot(loss_hist[:, i], label=labels[i]) # plot loss history on left\n",
        "        ax[1].plot(acc_hist[:, i], label=labels[i])  # plot accuracy history on right\n",
        "    \n",
        "    # add lables and title\n",
        "    ax[0].set_xlabel(\"Epochs\")\n",
        "    ax[0].set_ylabel(\"Loss\")\n",
        "    ax[0].legend()\n",
        "    ax[1].set_xlabel(\"Epochs\")\n",
        "    ax[1].set_ylabel(\"Accuracy\")\n",
        "    ax[1].legend()\n",
        "    f.suptitle(title, fontsize=14, y=1.03)\n",
        "    return plt.tight_layout()"
      ],
      "metadata": {
        "id": "5te4wQeM-3g9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would use momentum-based updates."
      ],
      "metadata": {
        "id": "UJziQPlxynnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_gradients(self, grad_weights, grad_biases, alpha_scaling=1):\n",
        "    alpha = self.alpha/alpha_scaling\n",
        "    gamma = self.gamma\n",
        "\n",
        "    # update momemtums\n",
        "    self.bias_momentums   = [gamma*V + alpha*W for V, W in zip(self.bias_momentums, grad_biases)]\n",
        "    self.weight_momentums = [gamma*V + alpha*W for V, W in zip(self.weight_momentums, grad_weights)]\n",
        "    \n",
        "    # update weights and biases\n",
        "    self.biases  = [W - V for W, V in zip(self.biases, self.bias_momentums)]\n",
        "    self.weights = [W - V for W, V in zip(self.weights, self.weight_momentums)]\n",
        "\n",
        "# expand Network definition\n",
        "Network.apply_gradients = apply_gradients"
      ],
      "metadata": {
        "id": "fPbThi-ayrf3"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now write the training function for our network."
      ],
      "metadata": {
        "id": "FQaLNrY7MJAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(self, Xs, Ys, loss, accuracy, epochs, alpha=0.1, gamma=0.9, initvel=1e-5):\n",
        "    # Xs = [X_train, X_valid (optional), X_test (optional)]\n",
        "    # Ys = [ys_train, ys_valid (optional), ys_test (optional)]\n",
        "    loss_hist = np.empty((0,Xs.shape[0]), float)\n",
        "    acc_hist  = np.empty((0,Xs.shape[0]), float)\n",
        "\n",
        "    # initialize momentums\n",
        "    self.alpha = alpha\n",
        "    self.gamma = gamma\n",
        "    self.bias_momentums   = [np.full((1, n), initvel) for n in self.sizes[1:]]\n",
        "    self.weight_momentums = [np.full((m, n), initvel) for m, n in \n",
        "                             zip(self.sizes[:-1], self.sizes[1:])]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # apply gradient descent\n",
        "        grad_weights, grad_biases = self.back_prop(Xs[0], Ys[0], loss)\n",
        "        self.apply_gradients(grad_weights, grad_biases, alpha_scaling=Xs[0].shape[0])\n",
        "\n",
        "        # compute current loss and accuracy\n",
        "        outputs   = [self.fwd_prop(Xs[i]) for i in range(Xs.shape[0])]\n",
        "        loss_hist = np.append(loss_hist, [[loss(outputs[i], Ys[i])/Xs[i].shape[0] for i in range(Xs.shape[0])]], axis=0)\n",
        "        acc_hist  = np.append(acc_hist, [[accuracy(outputs[i], Ys[i]) for i in range(Xs.shape[0])]], axis=0)\n",
        "\n",
        "        # print progress\n",
        "        if epoch % 20 == 0:\n",
        "            print(f\"Epoch {epoch} | Training Loss: {loss_hist[-1, 0]} Training Accuracy: {acc_hist[-1, 0]}\")\n",
        "\n",
        "    return self.weights, self.biases, loss_hist, acc_hist\n",
        "\n",
        "# expand Network defintion\n",
        "Network.train = train"
      ],
      "metadata": {
        "id": "BshhqOy7MMDM"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test it:"
      ],
      "metadata": {
        "id": "3wK00-78MaKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# recreate network (due to updates to class definition) and train on data\n",
        "nn = Network([F, H, K], [ReLU(), Softmax()])\n",
        "_, _, three_lyr_loss_hist, three_lyr_accuracy_hist = nn.train(Xs, Ys, CrossEntropy(), accuracy, 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILFIm_o9McKq",
        "outputId": "fdd9b5a5-1398-4647-cb32-dcb4dc44580c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Training Loss: 2.375626022023701 Training Accuracy: 0.2665\n",
            "Epoch 20 | Training Loss: 0.4207333231947012 Training Accuracy: 0.8865\n",
            "Epoch 40 | Training Loss: 0.30412885450972155 Training Accuracy: 0.9132\n",
            "Epoch 60 | Training Loss: 0.2538062655623269 Training Accuracy: 0.9288\n",
            "Epoch 80 | Training Loss: 0.21788812767121782 Training Accuracy: 0.9398\n",
            "Epoch 100 | Training Loss: 0.1891358401826244 Training Accuracy: 0.9486\n",
            "Epoch 120 | Training Loss: 0.1647921682497029 Training Accuracy: 0.9579\n",
            "Epoch 140 | Training Loss: 0.14381952617954716 Training Accuracy: 0.9649\n",
            "Epoch 160 | Training Loss: 0.12557783392061336 Training Accuracy: 0.972\n",
            "Epoch 180 | Training Loss: 0.10972784637818538 Training Accuracy: 0.9782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title = r\"Gradient Descent for 3 Layer Dense Network with $\\alpha={}$ and $\\gamma$={}\".format(0.1, 0.9)\n",
        "plot_learning_history(title, three_lyr_loss_hist, three_lyr_accuracy_hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "ctwAdJ5L0jZ4",
        "outputId": "a5fc3021-2663-4990-e26c-3eb8837cbd7a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a 4 layer network with an additional sigmoid layer to the previous network\n",
        "nn = Network([F, H, H, K], [ReLU(), Sigmoid(), Softmax()])\n",
        "_, _, four_lyr_loss_hist, four_lyr_accuracy_hist = nn.train(Xs, Ys, CrossEntropy(), accuracy, 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "DP41jWRCkbiN",
        "outputId": "b04e656d-41c4-49b1-9c61-215e2cd063b3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Training Loss: 2.6519416036731402 Training Accuracy: 0.1051\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-b7bb4dbca629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# recreate network (due to updates to class definition) and train on data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfour_lyr_loss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfour_lyr_accuracy_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossEntropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-54-af4228b24ff3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, Xs, Ys, loss, accuracy, epochs, alpha, gamma, initvel)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# compute current loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfwd_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0macc_hist\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-af4228b24ff3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# compute current loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfwd_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0macc_hist\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-0e3c353189b2>\u001b[0m in \u001b[0;36mfwd_prop\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mX_ell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m   \u001b[0;31m# X_0 (input layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mX_ell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ell\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute X_l, 0 < l <= L\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX_ell\u001b[0m \u001b[0;31m# X_L (output layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-97af780f85fc>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;31m# derivative of sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title = r\"Gradient Descent for 4 Layer Dense Network with $\\alpha={}$ and $\\gamma$={}\".format(0.1, 0.95)\n",
        "plot_learning_history(title, four_lyr_loss_hist, four_lyr_accuracy_hist)"
      ],
      "metadata": {
        "id": "eJCCvGI4kePi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
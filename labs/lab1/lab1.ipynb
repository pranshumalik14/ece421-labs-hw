{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1A_tNKGCLmCrQZGujHuIZhwkEe1mxQJHo",
      "authorship_tag": "ABX9TyMuLRomYxleim9G35pMSLc/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranshumalik14/ece421-labs-hw/blob/main/labs/lab1/lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 1: Logistic Regression\n",
        "\n",
        "In this lab, we will be creating a binary classifier using Logistic Regression first implemented using Numpy and then using Tensorflow. The classifier has to be trained on the `notMNIST` dataset, and particularly classify only between the letters `C` (positive class, labelled `1`) and `J` (negative class, labelled `0`). This dataset, representing the ground truth, will be represented as $\\mathcal{D}= \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$, where there are $N$ datavectors $\\mathbf{x}_i \\in \\mathbb{R}^d$ and labels $y_i \\in \\{0, 1\\}$."
      ],
      "metadata": {
        "id": "4nyBLeZpQvLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Logistic Regression with Numpy\n",
        "\n",
        "We use the following model for computing the probability of a datavector $\\mathbf{x}_n\\in\\mathbb{R}^d$ belonging to a particular class $y_n\\in \\{0, 1\\}$:\n",
        "\n",
        "$$\\hat{p}_\\mathbf{w}(y_n\\mid \\mathbf{x}_n) = \\sigma\\left((2y_n-1)(\\mathbf{w}^\\top\\mathbf{x}_n + b)\\right),$$\n",
        "\n",
        "given the model parameters $\\mathbf{w} \\in \\mathbb{R}^d$ (wieght) and $b \\in \\mathbb{R}$ (bias), and the logistic (or sigmoid) function $\\sigma(z) = \\frac{1}{1+e^{-z}}$.\n",
        "\n",
        "However, to simply expressions we will augment our datavectors $\\mathbf{x}_i$ with ones and accordingly increment the dimension of the weightvector, such that $\\mathbf{x}_i = \\begin{bmatrix}1 & x_1 & \\ldots & x_d\\end{bmatrix} \\in \\mathbb{R}^{d+1}$ and $\\mathbf{w} = \\begin{bmatrix}b & w_1 & \\ldots & w_d \\end{bmatrix}\\in \\mathbb{R}^{d+1}$. This will yield the (binary) label prediction probability to be:\n",
        "\n",
        "$$\\hat{p}_\\mathbf{w}(y_n\\mid \\mathbf{x}_n) = \\sigma\\left((2y_n-1)(\\mathbf{w}^\\top\\mathbf{x}_n)\\right).$$\n",
        "No changes are made to the label sequence $y_i$. Also note that the corresponding changes to function signatures were made, so the functions defined in this document (e.g. `loss` and `grad_loss`) will differ slightly from the lab handout."
      ],
      "metadata": {
        "id": "tIcxM0u-csSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Loss Function and Gradient \n",
        "\n",
        "We will use the regularized loss function (in-sample error) for minimization while training over the dataset:\n",
        "\n",
        "$$\\begin{align*}\n",
        "E_{\\text{in}, \\lambda}(\\mathbf{w}) &= \\lambda||\\mathbf{w}||^2 + \\frac{1}{N}\\sum_{n=1}^N -\\log\\left(\\hat{p}_\\mathbf{w}(y_n\\mid \\mathbf{x}_n)\\right)\\\\\n",
        "&= \\lambda||\\mathbf{w}||^2 + \\frac{1}{N}\\sum_{n=1}^N \\big[-I(y_n=1)\\log(\\hat{p}_\\mathbf{w}(1\\mid \\mathbf{x}_n)) -I(y_n=0)\\log(\\hat{p}_\\mathbf{w}(0\\mid \\mathbf{x}_n))\\big] \\quad \\triangleright \\text{since } y_n \\text{ only has two possibilities}\\\\\n",
        "&= \\lambda||\\mathbf{w}||^2 + \\frac{1}{N}\\sum_{n=1}^N \\big[-y_n\\log(\\hat{p}_\\mathbf{w}(1\\mid \\mathbf{x}_n)) -(1-y_n)\\log(1-\\hat{p}_\\mathbf{w}(1\\mid \\mathbf{x}_n))\\big]\\\\\n",
        "&= \\lambda||\\mathbf{w}||^2 + \\frac{1}{N}\\sum_{n=1}^N \\big[y_n\\log(1 + e^{-\\mathbf{w}^\\top\\mathbf{x}_n})) +(1-y_n)\\log(1+e^{\\mathbf{w}^\\top\\mathbf{x}_n})\\big],\n",
        "\\end{align*}\n",
        "$$\n",
        "where $\\lambda > 0$ is the regularization constant and $I(p)$ is the identifier function defined to be, $I(p) = \\begin{cases}1 & \\text{predicate } p \\text{ is true}\\\\ 0 & \\text{predicate } p \\text{ is false}\\end{cases}$\n",
        "\n",
        "The gradient of the loss function is:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "∇_{\\mathbf{w}}E_{\\text{in}, \\lambda}(\\mathbf{w}) &= ∇_{\\mathbf{w}}\\lambda||\\mathbf{w}||^2 + \\frac{1}{N}\\sum_{n=1}^N ∇_{\\mathbf{w}}\\big[-y_n\\log(\\hat{p}_\\mathbf{w}(1\\mid \\mathbf{x}_n)) -(1-y_n)\\log(1-\\hat{p}_\\mathbf{w}(1\\mid \\mathbf{x}_n))\\big]\\\\\n",
        "&=2\\lambda\\mathbf{w} + \\frac{1}{N}\\sum_{n=1}^N\\big[-y_n(1+e^{-\\mathbf{w}^\\top\\mathbf{x}_n})∇_{\\mathbf{w}}(1+e^{-\\mathbf{w}^\\top\\mathbf{x}_n})^{-1}-(1-y_n)(1+e^{\\mathbf{w}^\\top\\mathbf{x}_n})∇_{\\mathbf{w}}(1+e^{\\mathbf{w}^\\top\\mathbf{x}_n})^{-1}\\big]\\\\\n",
        "&=2\\lambda\\mathbf{w} + \\frac{1}{N}\\sum_{n=1}^N\\big[-y_n\\mathbf{x}_n\\underbrace{\\frac{e^{-\\mathbf{w}^\\top\\mathbf{x}_n}}{(1+e^{-\\mathbf{w}^\\top\\mathbf{x}_n})}}_{\\sigma(-\\mathbf{w}^\\top\\mathbf{x}_n) = 1-\\sigma(\\mathbf{w}^\\top\\mathbf{x}_n)}+(1-y_n)\\mathbf{x}_n\\underbrace{\\frac{e^{\\mathbf{w}^\\top\\mathbf{x}_n}}{(1+e^{\\mathbf{w}^\\top\\mathbf{x}_n})}}_{\\sigma(\\mathbf{w}^\\top\\mathbf{x}_n)}\\big]\\\\\n",
        "&=2\\lambda\\mathbf{w} + \\frac{1}{N}\\sum_{n=1}^N \\mathbf{x}_n\\left(\\sigma(\\mathbf{w}^\\top\\mathbf{x}_n)-y_n\\right)\\\\\n",
        "&=2\\lambda\\mathbf{w} + \\frac{1}{N}\\mathbf{X}^\\top\\left(\\boldsymbol{\\sigma}(\\mathbf{X}\\mathbf{w})-\\mathbf{y}\\right), \n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "where $\\mathbf{X} = \\begin{bmatrix}\\mathbf{x}_1^\\top\\\\\\vdots\\\\\\mathbf{x}_N^\\top\\end{bmatrix}\\in \\mathbb{R}^{N\\times(d+1)}$ is the datamatrix, $\\mathbf{y} \\in \\{0,1\\}^{N}$ is the labelvector, and $\\boldsymbol{\\sigma}(\\cdot)$ is a vector function acting element-wise on the input vector by applying the (scalar) logistic function."
      ],
      "metadata": {
        "id": "KgmTrGuPkxCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Iz52X8Wu_D4Z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid = lambda z: 1 / (1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "cehSNA51nnQt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(w, X, ys, reg_lambda):\n",
        "    Xw = X @ w\n",
        "    logit_CE_loss = ys*np.log(1 + np.exp(-Xw)) + (1 - ys)*np.log(1 + np.exp(Xw))\n",
        "    # return regularization penalty + cross entropy loss\n",
        "    return reg_lambda*np.linalg.norm(w)**2 + np.mean(logit_CE_loss)"
      ],
      "metadata": {
        "id": "6B3qA2QDQ8h8"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_loss(w, X, ys, reg_lambda):\n",
        "    return 2*reg_lambda*w + 1/X.shape[0]*(X.T @ (sigmoid(X@w) - ys))"
      ],
      "metadata": {
        "id": "BB2nSCFZtaCQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Gradient Descent Implementation\n",
        "\n",
        "The update step is:\n",
        "\n",
        "$$\\mathbf{w}_{k+1} = \\mathbf{w}_k - ϵ\\underbrace{∇_{\\mathbf{w}}E_{\\text{in}, λ}(\\mathbf{w}_k)}_{\\texttt{grad_loss}(\\mathbf{w}_k)},$$\n",
        "\n",
        "This is batch GD, with batch size N\n",
        "\n",
        "where $ϵ > 0$ is the learning rate."
      ],
      "metadata": {
        "id": "se9KDMkrv42r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_descent(w, Xs, Ys, eps, epochs, reg_lambda, error_tol=1e-7):\n",
        "    # Xs = [X_train, X_valid]\n",
        "    # Ys = [ys_train, ys_valid]\n",
        "    w_opt     = np.copy(w)\n",
        "    loss_hist = np.empty((0,2), float)\n",
        "    acc_hist  = np.empty((0,2), float)\n",
        "    for i in range(epochs):\n",
        "        grad_w = grad_loss(w, Xs[0], Ys[0], reg_lambda)\n",
        "        w_opt  = w - eps*grad_w\n",
        "        if np.linalg.norm(w-w_opt)**2 < error_tol:\n",
        "            break\n",
        "        else:\n",
        "            w = w_opt\n",
        "        loss_hist = np.append(loss_hist, [[loss(w, Xs[0], Ys[0], reg_lambda), loss(w, Xs[1], Ys[1], reg_lambda)]], axis=0)\n",
        "    return w_opt, loss_hist, acc_hist"
      ],
      "metadata": {
        "id": "iEitGSOafDDt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will test it on the data. The `notMNIST` dataset has images of size $28\\times 28$, thus we have $d=784$. "
      ],
      "metadata": {
        "id": "PsrzemJdfE0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "def loadDataGDrive():\n",
        "    with np.load('/content/drive/MyDrive/Colab Notebooks/notMNIST.npz') as dataset:\n",
        "        Data, Target = dataset['images'], dataset['labels']\n",
        "        posClass = 2\n",
        "        negClass = 9\n",
        "        dataIndx = (Target==posClass) + (Target==negClass)\n",
        "        Data = Data[dataIndx]/255.\n",
        "        Target = Target[dataIndx].reshape(-1, 1)\n",
        "        Target[Target==posClass] = 1\n",
        "        Target[Target==negClass] = 0\n",
        "        np.random.seed(421)\n",
        "        randIndx = np.arange(len(Data))\n",
        "        np.random.shuffle(randIndx)\n",
        "        Data, Target = Data[randIndx], Target[randIndx]\n",
        "        trainData, trainTarget = Data[:3500], Target[:3500]\n",
        "        validData, validTarget = Data[3500:3600], Target[3500:3600]\n",
        "        testData, testTarget = Data[3600:], Target[3600:]\n",
        "    return trainData, validData, testData, trainTarget, validTarget, testTarget\n",
        "\n",
        "x_train, x_valid, x_test, ys_train, ys_valid, ys_test = loadDataGDrive()"
      ],
      "metadata": {
        "id": "kSQHXyZX_f8R"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# augment datavectors\n",
        "X_train = np.concatenate([np.ones((x_train.shape[0])).reshape(-1, 1), x_train.reshape(x_train.shape[0], -1)], axis=1)\n",
        "X_valid = np.concatenate([np.ones((x_valid.shape[0])).reshape(-1, 1), x_valid.reshape(x_valid.shape[0], -1)], axis=1)\n",
        "X_test  = np.concatenate([np.ones((x_test.shape[0])).reshape(-1, 1), x_test.reshape(x_test.shape[0], -1)], axis=1)"
      ],
      "metadata": {
        "id": "Npi0SUmwopC3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run grad_desc (output optimal things)\n",
        "Xs     = np.array([X_train, X_valid], dtype=object)   # training and validation data\n",
        "Ys     = np.array([ys_train, ys_valid], dtype=object) # training and validation labels\n",
        "w_init = np.random.normal(0.001, 0.99, (X_train.shape[1], 1)) # initial weight vector\n",
        "w_star, loss_history, accuracy_history = grad_descent(w_init, Xs, Ys, 0.0001, 5000, 0)"
      ],
      "metadata": {
        "id": "DvIkYG2RfJeA"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_history[:, 0])\n",
        "plt.plot(loss_history[:, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ciBhN5Pjohcm",
        "outputId": "58d288e7-e367-45ed-ba3c-91db83e3ee83"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fdb87868610>]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Tuning the Learning Rate"
      ],
      "metadata": {
        "id": "B5kN_yGowGdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Generalization\n"
      ],
      "metadata": {
        "id": "Rlixb3nBwLR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kfwX31nhwUDj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Logistic Regression in TensorFlow\n"
      ],
      "metadata": {
        "id": "FS3R6sO3wVOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Building the Computational Graph"
      ],
      "metadata": {
        "id": "2Rm7M1wbfqdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "775Uvl6pRTnI"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Implementing Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "8hjWMY7efv6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Batch Size Investigation"
      ],
      "metadata": {
        "id": "819JblhHgEWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Hyperparameter Investigation"
      ],
      "metadata": {
        "id": "NzT_d9I_gHr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mKPlLfZkgMNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.5 Comparison against Batch Gradient Descent"
      ],
      "metadata": {
        "id": "MWYaddfagM2E"
      }
    }
  ]
}